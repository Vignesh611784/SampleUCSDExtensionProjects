# -*- coding: utf-8 -*-
"""PythonUSGSscraper_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18QH3EP4CpSmJFV_r51NKn-N98IpcvVx6

**Copyright: Â© NexStream Technical Education, LLC**.  
All rights reserved

# USGS Earthquake Scraper Introduction
In this project, you will create a 'web scraper' to access and retrieve real-time data from the US Geological Service (USGS) reflecting the latest active earthquakes around the world which are equal or above a user input magnitude.

The data is in JSON format so you'll need to convert the output into a user-readable (friendly) format.

The feed is from the USGS database here:  https://earthquake.usgs.gov/earthquakes/feed/.  You should become familiar with this site.

The format of the feed summary is here: https://earthquake.usgs.gov/earthquakes/feed/v1.0/geojson.php.  You should become familiar with the fields for the JSON data.  

Note you can use a JSON viewer for a more readable format of the data.

# Part 1a:  Setup the environment and script and prompt the user for input.
Setup the script imports and prompt the user for the magnitude from which the USGS data will be accessed.  That is, any earthquake greater than or equal to the input magnitude will be retrieved from the database.  
You'll need to import the urllib.request library to get to the web site.
You also can input the json library to utilize the functions in that library.
Check out both API's for reference.
"""

#Import the urllib.request and json libraries
import json
from google.colab import drive
import urllib.request
drive.mount('/content/drive/',force_remount=True)


#Prompt the user to input a magnitude parameter of type floating point.
#Limit the range that user can input to realistic magnitudes (check the magnitude entered and if it doesn't fall within a range, print out a message and prompt again.)
#Provide a prompt to the user to end the program or input another magnitude number (this code can be in a later cell).

param = 7.0
while param>5.4 or param<2.0:
  param = float(input('What maginitude are you going to see? '))

"""# Part 1b:  Write the printResults function.  
In this function, you should print the output of the data you retrieved from the site:  http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/2.5_day.geojson      
See the code comments for guided instruction.


Note you can use a JSON viewer for a more readable format of the data if you want to view it before processing it with your function.


"""

#Function printResults(data)
#In Python 3.x we need to explicitly decode the response to a string
#i.e. data is output from data.decode("utf-8")

def printResults(data):
  # Contents of the JSON file
  print(data['metadata'])

  #Prints the number of events
  print(len(data['features']))

  names = []

  #Prints the place each event occured
  for i in range(37):
    if float(data['features'][i]['properties']['mag']) > param:
      names.append(str(data['features'][i]['properties']['mag'])+' '+data['features'][i]['properties']['place'])
    else:
      names.append(data['features'][i]['properties']['place'])
  return names

  #5 For each event, if the magnitude is greater than the user input
  #  print both the magnitude and the place it occurred.
  #  HINT: use the "title" field that each feature has.
####Your code here....

"""# Part 1c:  Write the runner
In this code (either main or in a function), you should setup the URL from the USGS site, open the URL and read the data, call the printResults function.
http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/2.5_day.geojson  
See the code comments for guided instruction.  

Note you can use a JSON viewer for a more readable format of the data if you want to view it before processing it with your function.
"""

# Define a variable to hold the source URL (see the notes for the URL)
# This feed lists all earthquakes for the last day larger than Mag 2.5 (this is your minimum input)
!cp drive/My\ Drive/Colab\ Notebooks/'2.5_day.json' .

# Open the URL and read the data
# See urllib.request.urlopen API
dataJSON = ' '
with open('2.5_day.json') as f:
  dataJSON = json.load(f)

"""# Part 2:  Output data to spreadsheet
Convert output to CSV format.  

Rewrite the printResults function.  Call it printResults2(data) where a list or dictionary (your choice) is returned from the function to the runner then the data is converted to CSV format and saved to a file.

Change your runner to assign the returned data from your printResults2 function to a variable that you then convert to CSV format and save to a file.

Include at least the 4 retrieved from the database from Part 1.  
Include exception handling in your file IO processing.   
"""

#Prints the data into a csv file
import csv
outDataFile = open('OutputFuelConsumptionRatings.csv',mode = 'w')
dataWriter = csv.writer(outDataFile)
names = printResults(dataJSON)
for line in names:
  dataWriter.writerow(line)
  print(line)
outDataFile.close()
!cp OutputFuelConsumptionRatings.csv drive/My\ Drive/Colab\ Notebooks/