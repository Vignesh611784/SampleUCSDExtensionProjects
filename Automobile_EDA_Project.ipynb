{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUMkS64iV0hZ"
      },
      "source": [
        "**Copyright: Â© NexStream Technical Education, LLC**.  \n",
        "All rights reserved\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXdrZ6tv2RCd"
      },
      "source": [
        "# **Part 1:  Cleaning and Preprocessing Automobile Data**\n",
        "In this project, we will investigate automobile features from a dataset and preprocess the data.\n",
        "\n",
        "As we clean and explore this data, you will gain practice with:\n",
        "\n",
        "*  Reading simple csv files and using Pandas, Numpy, and Matplotlib\n",
        "*  Working with data at different levels of granularity\n",
        "*  Identifying the type of data collected, missing values, anomalies, etc.\n",
        "*  Exploring characteristics and distributions of individual variablesa\n",
        "\n",
        "The following list provides several example dataset links.  (these will be useful for future project assignments).\n",
        "- UCI: https://archive.ics.uci.edu/\n",
        "- Wikipedia:  https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research/\n",
        "- Kaggle:  https://www.kaggle.com/datasets/\n",
        "- National Geospatial Program:  https://www.usgs.gov/core-science-systems/national-geospatial-program/data-tools/\n",
        "- Seattle Central College Quant Environmental learning Project:  https://seattlecentral.edu/qelp/Data.html\n",
        "- Carnegie Mellon:  http://lib.stat.cmu.edu/datasets/\n",
        "- NIST:  https://www.itl.nist.gov/div898/strd/\n",
        "- MNIST:  https://chromium.googlesource.com/external/github.com/tensorflow/tensorflow/+/r0.7/tensorflow/g3doc/tutorials/mnist/download/index.md\n",
        "\n",
        "\n",
        "The following instructions are identified as Steps in the text cells preceding their corresponding code cell. Read through the instructions and write/fill-in the appropriate code in the cells.   \n",
        "\n",
        "Make sure your code passes all the embedded doctests."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXUObCU4Ogr7"
      },
      "source": [
        "**Step 1:**  \n",
        "Mount your Google drive and copy the provided files to your working directory.  Alternatively, you can read the file directly from the link provided in the cell below.\n",
        "- imports-85.csv\n",
        "- imports-85.names\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaKBTx2KPMO_",
        "outputId": "37f6bb5e-263a-47bf-ff00-d4d5116f4dd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "#Mounts the google drive\n",
        "import csv\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/',force_remount=True)\n",
        "!cp drive/My\\ Drive/Colab\\ Notebooks/'imports-85.csv' .\n",
        "!cp drive/My\\ Drive/Colab\\ Notebooks/'imports-85.names' ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aTZlcwI9uG_"
      },
      "source": [
        "**Step 2:**  \n",
        "Import all relevant python libraries:\n",
        "- numpy\n",
        "- pandas\n",
        "- matplotlib (pyplot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KsuoqzUR2rnt"
      },
      "outputs": [],
      "source": [
        "#Imports the libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjgUvoRnnyID"
      },
      "source": [
        "**Step 3:**  \n",
        "Read the auto data into a Pandas dataframe.  \n",
        "NAME YOUR DATAFRAME VARIABLE '**data**' to be compatible with the embedded doctests.  Read the provided csv file directly.\n",
        "\n",
        "Note, you should set up a list of column headers according to the imports-85.names file.   \n",
        "Examine the first 5 rows of the dataset, and check out the dataset statistics.\n",
        "\n",
        "Hints:\n",
        "- https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n",
        "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html\n",
        "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwNM-x2q51NI",
        "outputId": "a58f5b95-904b-425c-bd47-291abd240c50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['symboling', 'normalized-losses', 'make', 'fuel-type', 'aspiration', 'num-of-doors', 'body-style', 'drive-wheels', 'engine-location', 'wheel-base', 'length', 'width', 'height', 'curb-weight', 'engine-type', 'num-of-cylinders', 'engine-size', 'fuel-system', 'bore', 'stroke', 'compression-ratio', 'horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg', 'price']\n",
            "26\n"
          ]
        }
      ],
      "source": [
        "#Reads the dataset directly from the provided link.\n",
        "#Creates a list of the headers according to the imports-85.names file.\n",
        "namesFile = open('imports-85.names', 'r')\n",
        "names = []\n",
        "num = 0\n",
        "for line in namesFile:\n",
        "  word = ''\n",
        "  for ch in line:\n",
        "    num = num + 1\n",
        "    if ch != ':' and num>5:\n",
        "      word = word + ch\n",
        "    elif ch == ':':\n",
        "      break\n",
        "  names.append(word)\n",
        "  num = 0\n",
        "print(names)\n",
        "print(len(names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7wO5oQvvLp8",
        "outputId": "5ea310fe-d9a2-4a9f-9222-fee5ee5f52ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(205, 26)\n"
          ]
        }
      ],
      "source": [
        "#Reads the dataset from the provided csv file\n",
        "#Creates a list of the headers according to the imports-85.names file.\n",
        "dataRead = pd.read_csv('imports-85.csv',header=None)\n",
        "data = pd.DataFrame(dataRead)\n",
        "dArray = np.array(data)\n",
        "data.columns = names\n",
        "print(data.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VR2voV2ozAjl"
      },
      "source": [
        "[link text](https://)**Step 4:**  \n",
        "Replace all the ?'s in the dataset with NaN.  \n",
        "Perform the operation 'in-place', meaning it replaces within the same object (not in another data structure).  \n",
        "Examine the first 5 rows to confirm your replacement.   \n",
        "Make sure your code passes the doctest.\n",
        "\n",
        "Hint:  https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1_JgtGizqZ3",
        "outputId": "684fa13d-8232-465b-e30f-d7b69a8948c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/lib/python3.10/doctest.py\", line 1501, in run\n",
            "    sys.settrace(save_trace)\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TestResults(failed=0, attempted=3)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#Replaces all ? with NaN\n",
        "data.replace('?', np.nan, inplace=True)\n",
        "\n",
        "#Doctest code\n",
        "import doctest\n",
        "\"\"\"\n",
        "  >>> print(data['normalized-losses'].iat[1])\n",
        "  nan\n",
        "  >>> print(data['peak-rpm'].iat[131])\n",
        "  nan\n",
        "  >>> print(data['horsepower'].iat[130])\n",
        "  nan\n",
        "\"\"\"\n",
        "\n",
        "doctest.testmod()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYi0hOMpzLYL"
      },
      "source": [
        "**Step 5:**  \n",
        "Find and count the missing data (i.e. the entries that were changed to NaN in the previous step).  \n",
        "Suggested method:\n",
        "*   First mark the missing data with \"True\"\n",
        "*   Count the \"True\" tags in a loop\n",
        "\n",
        "Make sure your code passes the doctest.\n",
        "\n",
        "Hints:\n",
        "- https://pandas.pydata.org/docs/reference/api/pandas.isnull.html\n",
        "- https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "A_ykFPDt16fD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7be2d90c-cbf6-4aba-cb4d-85f3d716bbf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**********************************************************************\n",
            "File \"__main__\", line 3, in __main__\n",
            "Failed example:\n",
            "    print(missing_data['normalized-losses'].value_counts())\n",
            "Expected:\n",
            "    False    164\n",
            "    True      41\n",
            "    Name: normalized-losses, dtype: int64\n",
            "Got:\n",
            "    normalized-losses\n",
            "    False    164\n",
            "    True      41\n",
            "    Name: count, dtype: int64\n",
            "**********************************************************************\n",
            "File \"__main__\", line 7, in __main__\n",
            "Failed example:\n",
            "    print(missing_data['symboling'].value_counts())\n",
            "Expected:\n",
            "    False    205\n",
            "    Name: symboling, dtype: int64\n",
            "Got:\n",
            "    symboling\n",
            "    False    205\n",
            "    Name: count, dtype: int64\n",
            "**********************************************************************\n",
            "File \"__main__\", line 10, in __main__\n",
            "Failed example:\n",
            "    print(missing_data['bore'].value_counts())\n",
            "Expected:\n",
            "    False    201\n",
            "    True       4\n",
            "    Name: bore, dtype: int64\n",
            "Got:\n",
            "    bore\n",
            "    False    201\n",
            "    True       4\n",
            "    Name: count, dtype: int64\n",
            "**********************************************************************\n",
            "File \"__main__\", line 14, in __main__\n",
            "Failed example:\n",
            "    print(missing_data['horsepower'].value_counts())\n",
            "Expected:\n",
            "    False    203\n",
            "    True       2\n",
            "    Name: horsepower, dtype: int64\n",
            "Got:\n",
            "    horsepower\n",
            "    False    203\n",
            "    True       2\n",
            "    Name: count, dtype: int64\n",
            "**********************************************************************\n",
            "1 items had failures:\n",
            "   4 of   4 in __main__\n",
            "***Test Failed*** 4 failures.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-b890da014cd6>:4: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
            "  missing_data.column = names\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TestResults(failed=4, attempted=4)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "#Detects and counts the missing data\n",
        "\n",
        "missing_data = pd.isna(data)\n",
        "missing_data.column = names\n",
        "\n",
        "for ii in range(missing_data.shape[1]):\n",
        "  missing_data[names[ii]].value_counts()\n",
        "\n",
        "#Doctest code: It outputs the right numbers, but it is showing that all the test cases failed because the code is printing incorrectly for some reason\n",
        "import doctest\n",
        "\"\"\"\n",
        "  >>> print(missing_data['normalized-losses'].value_counts())\n",
        "  False    164\n",
        "  True      41\n",
        "  Name: normalized-losses, dtype: int64\n",
        "  >>> print(missing_data['symboling'].value_counts())\n",
        "  False    205\n",
        "  Name: symboling, dtype: int64\n",
        "  >>> print(missing_data['bore'].value_counts())\n",
        "  False    201\n",
        "  True       4\n",
        "  Name: bore, dtype: int64\n",
        "  >>> print(missing_data['horsepower'].value_counts())\n",
        "  False    203\n",
        "  True       2\n",
        "  Name: horsepower, dtype: int64\n",
        "\"\"\"\n",
        "\n",
        "doctest.testmod()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NVVX1_SzOJ5"
      },
      "source": [
        "**Step 6:**  \n",
        "Now in order to perform an modeling on our dataset, we'll need to account for the missing data.  Some options include removing the row altogether, but this may also delete other meaningful data, so more common approaches include replacing missing data with a statistic, such as with the mean of the feature column or replacing it with the most common option of the feature.  \n",
        "Perform the following operations:\n",
        "1.   Replace missing data in the 'normalized-losses' feature with its mean.\n",
        "2.   Replace missing data 'num-of-doors' and 'bore' features with the most common option in their respective feature column.\n",
        "3.   Drop the example ROW if the 'price' feature is missing for that example.  Note, axis=0 drops whole row, axis=1 drops whole column\n",
        "\n",
        "Make sure your code passes the doctest.\n",
        "\n",
        "\n",
        "Hints:\n",
        "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html\n",
        "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mean.html\n",
        "- https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html\n",
        "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.idxmax.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rknq_HbH278x",
        "outputId": "674aff03-47cd-490b-9ed5-53338c6db073"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TestResults(failed=0, attempted=2)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#Replaces missing data in the 'normalized-losses' feature with its mean.\n",
        "\n",
        "colNLnoNAN = pd.Series(data['normalized-losses'].dropna())\n",
        "colMean = colNLnoNAN.astype(float).mean()\n",
        "data['normalized-losses'] = data['normalized-losses'].fillna(colMean)\n",
        "\n",
        "#Doctest code\n",
        "import doctest\n",
        "\"\"\"\n",
        "  >>> print(data['normalized-losses'].iat[1])\n",
        "  122.0\n",
        "  >>> print(data['normalized-losses'].iat[15])\n",
        "  122.0\n",
        "\"\"\"\n",
        "\n",
        "doctest.testmod()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggVP0XY44YXm",
        "outputId": "1eee89c6-ba19-4bc2-ae58-518b8027ef8d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TestResults(failed=0, attempted=2)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#Replaces missing data 'num-of-doors' and 'bore' features with the most common option in their respective feature column.\n",
        "\n",
        "doorType = np.array(data['num-of-doors'])\n",
        "if (np.shape(np.where(doorType == 'two'))[1] > np.shape(np.where(doorType == 'four'))[1]):\n",
        "  repDoor = 'two'\n",
        "else:\n",
        "  repDoor = 'four'\n",
        "data['num-of-doors'] = data['num-of-doors'].fillna(repDoor)\n",
        "\n",
        "from scipy import stats\n",
        "modeVal = stats.mode((data['bore'].dropna()).astype(float)).mode\n",
        "data['bore'] = data['bore'].fillna(modeVal)\n",
        "\n",
        "\n",
        "#Doctest code\n",
        "import doctest\n",
        "\"\"\"\n",
        "  >>> print(data['num-of-doors'].iat[27])\n",
        "  four\n",
        "  >>> print(data['bore'].iat[57])\n",
        "  3.62\n",
        "\"\"\"\n",
        "\n",
        "doctest.testmod()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbnyStVIDRLK",
        "outputId": "5e6d2f9a-7b5d-4edc-983a-6fbc54fe154d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TestResults(failed=0, attempted=1)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#Drops the example ROW if the 'price' feature is missing for that example.\n",
        "\n",
        "priceCol = np.array(data['price']).astype(float)\n",
        "noPrRow = np.argwhere(np.isnan(priceCol))[:,0]\n",
        "for ii in range(noPrRow.shape[0]):\n",
        "  data = data.drop(noPrRow[ii])\n",
        "\n",
        "#Doctest code\n",
        "import doctest\n",
        "\"\"\"\n",
        "  >>> print(len(data['price']))\n",
        "  201\n",
        "\"\"\"\n",
        "\n",
        "doctest.testmod()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJx6QsbfzQfV"
      },
      "source": [
        "**Step 7:**  \n",
        "We typically want any categorical data with string data types to be formatted as objects when preparing data for our machine learning model.  Also, any numeric values should be int or float types.  Finally, columns that have IDs typed as objects but are actually numeric values should be converted to their numeric types.  Perform the following on your dataset.\n",
        "*  Print out the data types\n",
        "*  Change data types for numeric columns that are identified as objects\n",
        "\n",
        "Compare the updated data types to the original print out to make sure they were updated.   \n",
        "Make sure your code passes the doctest.\n",
        "\n",
        "Hints:\n",
        "- bore, stroke, normalized-losses, peak-rpm all need to change.  Note, you will need to replace the NaNs as needed first (replace with mean of column).\n",
        "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dtypes.html\n",
        "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html\n",
        "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mean.html\n",
        "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hU8WTL1KNjW",
        "outputId": "a60fc95e-9632-4676-8d5f-3e6a4d5d4f4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TestResults(failed=0, attempted=1)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#Changes data types for numeric columns that are identified as objects\n",
        "\n",
        "data['bore'] = data['bore'].astype(float)\n",
        "data['stroke'] = data['stroke'].astype(float)\n",
        "data['normalized-losses'] = data['normalized-losses'].astype(int)\n",
        "data['price'] = data['price'].astype(float)\n",
        "\n",
        "rpmMean = pd.Series(data['normalized-losses'].dropna()).astype(float).mean()\n",
        "data['peak-rpm'] = data['peak-rpm'].fillna(rpmMean)\n",
        "data['peak-rpm'] = data['peak-rpm'].astype(int)\n",
        "\n",
        "\n",
        "#Doctest code\n",
        "import doctest\n",
        "\"\"\"\n",
        "  >>> print(data[['bore', 'stroke', 'normalized-losses', 'price', 'peak-rpm']].dtypes)\n",
        "  bore                 float64\n",
        "  stroke               float64\n",
        "  normalized-losses      int64\n",
        "  price                float64\n",
        "  peak-rpm               int64\n",
        "  dtype: object\n",
        "\"\"\"\n",
        "\n",
        "doctest.testmod()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F-TOHVp41bB"
      },
      "source": [
        "**Step 8:**  \n",
        "Many machine learning algorithms are sensitive to features with different ranges, for example, linear regression.  So, normalization is a common practice to implement on the data.\n",
        "\n",
        "*   Normalize the 'length', 'height' and 'width' columnsa\n",
        "\n",
        "Make sure your code passes the doctest.\n",
        "\n",
        "\n",
        "Hint:  there isn't a built-in Pandas function so a simply conversion is to divide each element by the feature maximum.\n",
        "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.max.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LWBDIaexUaq_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9871f713-eb31-4b80-9abe-9a0527ba5c38"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TestResults(failed=0, attempted=6)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#Normalizes the length, height, and width columns\n",
        "#Divides each element of column by its max value\n",
        "\n",
        "lengthCol = data['length'].astype(float)\n",
        "lengthCol = np.round((lengthCol/lengthCol.max()), 4)\n",
        "data['length'] = lengthCol\n",
        "\n",
        "heightCol = data['height'].astype(float)\n",
        "heightCol = np.round((heightCol/heightCol.max()), 4)\n",
        "data['height'] = heightCol\n",
        "\n",
        "widthCol = data['width'].astype(float)\n",
        "widthCol = np.round((widthCol/widthCol.max()), 4)\n",
        "data['width'] = widthCol\n",
        "\n",
        "#Below is the code for step 9\n",
        "\n",
        "#hpMean = (pd.Series(data['horsepower'].dropna())).astype(float).mean()\n",
        "#hp = np.array(data['horsepower'].fillna(hpMean)).astype(int)\n",
        "\n",
        "#hpBinLimits = np.linspace(np.min(hp), np.max(hp), 5)\n",
        "\n",
        "#ltLow = []\n",
        "#ltMedgtLow = []\n",
        "#ltHighgtMed = []\n",
        "#gtHigh = []\n",
        "\n",
        "#for ii in range(hp.shape[0]):\n",
        "#  if ((hp[ii] >= hpBinLimits[0]) and (hp[ii] < hpBinLimits[1])):\n",
        "#    ltLow = np.append(ltLow, hp[ii])\n",
        "#  elif ((hp[ii] >= hpBinLimits[1]) and (hp[ii] < hpBinLimits[2])):\n",
        "#    ltMedgtLow = np.append(ltMedgtLow, hp[ii])\n",
        "#  elif ((hp[ii] >= hpBinLimits[2]) and (hp[ii] < hpBinLimits[3])):\n",
        "#    ltHighgtMed = np.append(ltHighgtMed, hp[ii])\n",
        "#  else:\n",
        "#    gtHigh = np.append(gtHigh, hp[ii])\n",
        "\n",
        "#hpCounts = np.array([ltLow.shape[0], ltMedgtLow.shape[0], ltHighgtMed.shape[0], gtHigh.shape[0]])\n",
        "\n",
        "#plt.hist(hpBinLimits[:-1], hpBinLimits, weights=hpCounts)\n",
        "#plt.show()\n",
        "\n",
        "#[npCounts, npBins] = np.histogram(hp)\n",
        "\n",
        "#Doctest code\n",
        "import doctest\n",
        "\"\"\"\n",
        "  >>> print(np.round(data['length'].iat[0],4))\n",
        "  0.8111\n",
        "  >>> print(np.round(data['height'].iat[27],4))\n",
        "  1.0\n",
        "  >>> print(np.round(data['width'].iat[57],4))\n",
        "  0.9236\n",
        "  >>> print(np.round(data['length'].iat[3],4))\n",
        "  0.8486\n",
        "  >>> print(np.round(data['height'].iat[85],4))\n",
        "  0.8629\n",
        "  >>> print(np.round(data['width'].iat[163],4))\n",
        "  0.9111\n",
        "\"\"\"\n",
        "\n",
        "doctest.testmod()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Th0UMoym43O1"
      },
      "source": [
        "**Step 9:**  \n",
        "Data visualization - data binning\n",
        "\n",
        "*   Generate a histogram plot of the horsepower data into high, med, low bins\n",
        "*   Take a screenshot of your plot and paste it into a document to submit with this assignment.  Your plot should look similar to this:\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1ymbq21BzRcXh7jGKoHrQ1Dh-IKCT2STS)  \n",
        "\n",
        "\n",
        "Hints:\n",
        "- First replace any NaNs with the mean of the column, and convert objects to integers\n",
        "- Group the feature into 4 different ranges:  less than 'low', between 'low' and 'med', between 'med' and 'high', and greater than 'high.\n",
        "- Count the values in each of the ranges\n",
        "- Plot the bins on a histogram\n",
        "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html\n",
        "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mean.html\n",
        "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html\n",
        "- https://numpy.org/doc/stable/reference/generated/numpy.linspace.html\n",
        "- https://pandas.pydata.org/docs/reference/api/pandas.cut.html\n",
        "- https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "EGEQHkifWkqj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "82950277-730f-496e-c718-f5f326e0ec76"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Creates bin array with min, max and range using numpy linspace\n",
        "#and setups 3 bins (high, med, low) - 4 dividers in the histogram\n",
        "#Removes NaNs and convert objects to integers\n",
        "#Groups the feature into 4 different ranges: <= 'low', >'low' && <='med', >'med'&& <='high', >'high.\n",
        "#Counts the values in each of the ranges\n",
        "#Plots the bins on a histogram\n",
        "\n",
        "hpMean = (pd.Series(data['horsepower'].dropna())).astype(float).mean()\n",
        "hp = np.array(data['horsepower'].fillna(hpMean)).astype(int)\n",
        "data['horsepower'] = hp\n",
        "\n",
        "hpBinLimits = np.linspace(np.min(hp), np.max(hp), 5)\n",
        "\n",
        "ltLow = []\n",
        "ltMedgtLow = []\n",
        "ltHighgtMed = []\n",
        "gtHigh = []\n",
        "\n",
        "for ii in range(hp.shape[0]):\n",
        "  if ((hp[ii] >= hpBinLimits[0]) and (hp[ii] < hpBinLimits[1])):\n",
        "    ltLow = np.append(ltLow, hp[ii])\n",
        "  elif ((hp[ii] >= hpBinLimits[1]) and (hp[ii] < hpBinLimits[2])):\n",
        "    ltMedgtLow = np.append(ltMedgtLow, hp[ii])\n",
        "  elif ((hp[ii] >= hpBinLimits[2]) and (hp[ii] < hpBinLimits[3])):\n",
        "    ltHighgtMed = np.append(ltHighgtMed, hp[ii])\n",
        "  else:\n",
        "    gtHigh = np.append(gtHigh, hp[ii])\n",
        "\n",
        "hpCounts = np.array([ltLow.shape[0], ltMedgtLow.shape[0], ltHighgtMed.shape[0], gtHigh.shape[0]])\n",
        "\n",
        "plt.hist(hpBinLimits[:-1], hpBinLimits, weights=hpCounts)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCwNagFgjfg7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_7LjPHgaKO-"
      },
      "source": [
        "**Step 10:**  \n",
        "Write the preprocessed dataset to a csv file\n",
        "\n",
        "Hint:\n",
        "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html\n",
        "- Use '!cp' to copy the file to a folder on your Google drive\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Z37Ek3p9bA-8"
      },
      "outputs": [],
      "source": [
        "#Writes preprocessed dataset to csv file\n",
        "import csv\n",
        "outDataFile = open('Output.csv',mode = 'w')\n",
        "data.to_csv(outDataFile, sep=',')\n",
        "!cp Output.csv drive/My\\ Drive/Colab\\ Notebooks/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOXA_6YABxiX"
      },
      "source": [
        "# **Part 2:  Modeling your Pre-processed Automobile Data**\n",
        "Now that you have cleaned your dataset you are ready to apply a machine learning model.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Simple Linear Regression - Manual Calculation**  \n",
        "\n",
        "In this part, you will perform a manual calculation of the coefficients used in a simple linear regression model for a given dataset.  For now, just follow the steps outlined in the following procedure - we will discuss Regression in depth in the Machine Learning Algorithms course.\n",
        "\n",
        "We will attempt to fit a simple linear regression model using 2 features from the cleaned dataset.  The model \"score\" will help us determine how well one variable can predict another.\n",
        "\n",
        "Please complete the following steps in your Colab Script.  The reference script below provides template code and hints to help with each step.  \n",
        "\n",
        "-  **Step 1**:  Create a function which MANALLY (using the equations below) calculates the coefficients for a simple linear regression model.\n",
        "  - Inputs:  X = dataset independent variable, y = dataset dependent variable\n",
        "  - Return: coefficients b0, and b1\n",
        "\n",
        "  (NOTE, you may NOT use any machine learning library models for this step - you must calculate the parameters use the equations shown).  \n",
        "\n",
        "$$\\hat y = b_0+b_1x_1$$  \n",
        "$$b_1=\\frac {\\sum\n",
        "(x_n-\\bar x)(y_n-\\bar y)} {\\sum\n",
        "(x_n-\\bar x)^2}\n",
        "$$  \n",
        "$$b_0=\\bar y-b_1\\bar x$$  \n",
        "\n",
        "-  **Step 2**: Create a function which generates a predicted output y_hat using the prediction equation from the previous step.\n",
        "  - Inputs:  X = dataset independent variable, coefs = regression model coefficients (b0, b1)\n",
        "  - Return: predicted output y_hat\n",
        "-  **Step 3**: Create a function which plots the dataset (X, y) and the calculated regression line (equation of the prediction line y_hat)\n",
        "  - Inputs:  X = dataset independent variable, y = dataset dependent variable, y_hat = predicted output\n",
        "  - Return: none\n",
        "-  **Step 4**:  Create a function which calculates the performance using R-squared using sklearn r2_score function (you may use the sklearn library for this step). Read the documentation on this function to get a feel for the range and interpretation of this score.  We will discuss R-squared scores in detail when covering Regression, but for now, you may simply call the sklearn function. See https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html\n",
        "  - Inputs: y = actual dependent variables, y_hat = predicted output based on calculated regression line\n",
        "  - Return: R_squared value\n",
        "-  **Step 5**:  Confirm your calculated coefficients and R-squared performance metric using the embedded doctest module.  Record your regression equation.\n",
        "The doctest will attempt to call your plot function and package it into a set of subplots, which should like the following:\n",
        "<br>\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1P_dukwYyzHGvuLj4NOLMnAtJFIJ8Ywr-)  \n",
        "\n",
        "-  **Step 6**:  Reflect on the performance of your model.  What does the R-squared parameter tell you about the properties of this dataset and your simple linear prediction?  Which of the independent variables best predicted the normalized-losses variable?  Given the R-squared scores you saw, is this a good model?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "XESp9Oy-Bxih",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db606e06-9d10-4a5c-e8a1-a6cd3509ec44"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TestResults(failed=0, attempted=7)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "\n",
        "#         Creates a function which MANALLY (using the equations) calculates the\n",
        "#         coefficients for a simple linear regression model.\n",
        "#         Your function must input numpy arrays for the X and y variables and return b0 and b1.\n",
        "#         Your function MUST use equations shown in the text cell above.\n",
        "#         (i.e. - you may not use a Machine Learning library API for this step,\n",
        "#                 calculate the parameters use the equations above).\n",
        "#         Inputs:  X = dataset independent variable, y = dataset dependent variable\n",
        "#         Return: coefficients b0, and b1\n",
        "def simple_LR_coefs(x, y):\n",
        "\n",
        "  xIn = np.array(x)\n",
        "  yIn = np.array(y)\n",
        "\n",
        "  xMean = np.mean(xIn)\n",
        "  yMean = np.mean(yIn)\n",
        "\n",
        "  b1 = np.sum((yIn - yMean) * (xIn - xMean))/np.sum((xIn - xMean)**2)\n",
        "  b0 = yMean - b1 * xMean\n",
        "\n",
        "  return b0, b1\n",
        "\n",
        "#               Creates a function which generates a predicted output y_hat\n",
        "#               using the prediction equation in the text cell above.\n",
        "#               Your function MUST use equations shown in the text cell above.\n",
        "#               (i.e. - you may not use a Machine Learning library API)\n",
        "#               Inputs:  X = dataset independent variable,\n",
        "#                        coefs = regression model coefficients (b0, b1)\n",
        "#               Return: predicted output y_hat\n",
        "def prediction(x, coefs):\n",
        "\n",
        "  xIn = np.array(x)\n",
        "  y_hat = coefs[0] + coefs[1] * x\n",
        "\n",
        "  return y_hat\n",
        "\n",
        "\n",
        "#         Creates a function plots the dataset and the calculated regression line\n",
        "#         Inputs:  X = dataset independent variable, y = dataset dependent variable,\n",
        "#                  y_hat = predicted output\n",
        "#         Return: none\n",
        "def plot(x, y, y_hat):\n",
        "  xIn = np.array(x)\n",
        "  yIn = np.array(y)\n",
        "  yHatIn = np.array(y_hat)\n",
        "\n",
        "  plt.plot(xIn, yIn, 'yo', xIn, yHatIn, '--k')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "#         Creates a function which calculates the performance using R-squared using sklearn r2_score function.\n",
        "#         Inputs: y = actual dependent variables, y_hat = predicted output based on calculated regression line\n",
        "#         Return: R_squared value\n",
        "#         Hint:  see https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html\n",
        "def score(y, y_hat):\n",
        "  yHatIn = np.array(y_hat)\n",
        "  yIn = np.array(y)\n",
        "\n",
        "  score = r2_score(y, y_hat)\n",
        "\n",
        "  return score\n",
        "\n",
        "\n",
        "#Doctest code\n",
        "\n",
        "import doctest\n",
        "X_test = np.array([data['normalized-losses'],\n",
        "                   data['length'],\n",
        "                   data['horsepower'],\n",
        "                   data['symboling']])\n",
        "\n",
        "y = data['normalized-losses']\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "  >>> print(np.round(simple_LR_coefs(X_test[0], y), 5))\n",
        "  [0. 1.]\n",
        "  >>> print(np.round(score(y, prediction(X_test[0], (simple_LR_coefs(X_test[0], y)))), 5))\n",
        "  1.0\n",
        "  >>> print(np.round(score(y, prediction(X_test[1], (simple_LR_coefs(X_test[1], y)))), 5))\n",
        "  0.00038\n",
        "  >>> print(np.round(simple_LR_coefs(X_test[2], y), 5))\n",
        "  [102.76122   0.18607]\n",
        "  >>> print(np.round(score(y, prediction(X_test[2], (simple_LR_coefs(X_test[2], y)))), 5))\n",
        "  0.04722\n",
        "  >>> print(np.round(simple_LR_coefs(X_test[3], y), 5))\n",
        "  [112.00354  11.88928]\n",
        "  >>> print(np.round(score(y, prediction(X_test[3], (simple_LR_coefs(X_test[3], y)))), 5))\n",
        "  0.2174\n",
        "\"\"\"\n",
        "\n",
        "doctest.testmod()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}